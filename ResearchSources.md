Contains the link for all resources used:

# used to select which neural network model to train:
https://medium.com/@nick.nagari/comparing-4-popular-open-source-speech-to-text-neural-network-models-92676a9f9265
https://fosspost.org/open-source-speech-recognition/
https://officechai.com/stories/indian-govt-releases-version-of-openais-whisper-model-which-turns-hindi-speech-into-text/

# model selected:
https://huggingface.co/vasista22/whisper-hindi-large-v2  

# used for data prep, finetuning, testing:
https://huggingface.co/blog/fine-tune-whisper
https://huggingface.co/openai/whisper-medium

# used for dataset (Hindi train - 95.05 hours and test - 5.55 hours) all labelled:
http://www.openslr.org/103/

# OVERVIEW OF ASRs: (according to chatGPT)
Automatic Speech Recognition (ASR) systems primarily transcribe audio input to text. ASR systems are designed to convert spoken language into written text, making them useful in applications such as transcription services, voice assistants, and voice command recognition.

The typical workflow of an ASR system involves the following steps:

Audio Input: The ASR system takes in audio as input. This audio can come from various sources, such as a microphone recording, audio file, or streaming audio.

Acoustic Feature Extraction: The audio signal is processed to extract acoustic features that represent the spectral content of the speech signal. Commonly used features include Mel frequency cepstral coefficients (MFCCs) or filterbank energies. These features capture the time-varying information of the audio.

Acoustic Modeling: The extracted acoustic features are fed into a statistical model, such as a Hidden Markov Model (HMM) or deep neural network (DNN). This model has been trained on a large amount of labeled speech data to learn the relationship between the acoustic features and the corresponding phonetic units or subword units.

Language Modeling: In addition to the acoustic modeling, ASR systems often employ a language model to improve the transcription accuracy. A language model considers the statistical properties of language, such as word sequences and grammar rules, to provide additional context and improve the likelihood estimation of the transcriptions.

Decoding: The acoustic and language models work together to generate a sequence of likely word or phoneme transcriptions for the given audio input. This process is known as decoding. Different decoding algorithms, such as Hidden Markov Model-Decoding or beam search, are used to find the most probable transcription based on the models' probabilities.

Post-processing: The output of the decoding step is usually a sequence of word or phoneme transcriptions. This output might undergo additional post-processing steps, such as language-dependent pronunciation mapping, word capitalization, punctuation insertion, or other language-specific rules to refine the final transcription.

ASR systems primarily rely on the audio input to transcribe and convert speech into written text. The models and algorithms employed in ASR systems are trained using labeled audio and corresponding transcriptions to learn the mapping between acoustic features and linguistic units.
